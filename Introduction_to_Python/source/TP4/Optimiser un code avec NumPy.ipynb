{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5697ee",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f9756f9f3831234",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd291b2",
   "metadata": {},
   "source": [
    "# Bonnes pratiques en NumPy\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/1280px-NumPy_logo_2020.svg.png\" width=\"256px\" align=\"left\"/>\n",
    "\n",
    "Les séances précédentes avaient pour objectifs de vous familiariser avec les différentes librairies formant l'écosystème `python scientifique`.\n",
    "Nous nous sommes notamment intéresser à la bibliothèque **NumPy**.\n",
    "Cette dernière fournie toutes les briques de base nécessaires pour le calcul scientifique en `python`, notamment la structure données connue sous le nom de `numpy array`.\n",
    "**NumPy** fournit également une ensemble de fonctions mathématiques opérant sur ces tableaux.\n",
    "Bien qu'il s'agisse d'une bibliothèque Python, la plupart de ses fonctions sont écrites dans un langage de plus bas niveau tel que [Fortran](https://fr.m.wikipedia.org/wiki/Fortran) ou [C](https://fr.m.wikipedia.org/wiki/C_(langage)).\n",
    "L'utilisation de tels langages pour la partie calculatoire permet de garantir d'excellentes performances tandis que l'interface Python simplifie fortement l'utilisation de ces fonctions.\n",
    "\n",
    "Dans le cadre du présent TP, nous allons maintenant nous intéresser aux bonnes pratiques devant être mises en oeuvre afin de tirer parti au maximum des performances de **NumPy**.\n",
    "Pour cela, plusieurs bouts de code vous sont présentés ci-dessous.\n",
    "Pour chacun d'entre eux, votre objectif est non seulement de comprendre ce qu'ils font (une rapide description vous est néanmoins donnée en préambule), mais aussi de les ré-écrire de façon plus efficace (notamment en *vectorisant* ce qui peut être vectorisé)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c58b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Méthode des moindres carrés\n",
    "\n",
    "Le cadre d'application de ce TP sera la [méthode des moindres carrés](https://fr.wikipedia.org/wiki/M%C3%A9thode_des_moindres_carr%C3%A9s).\n",
    "Cette méthode, développée indépendamment au début du XIXe siècle par le mathématicien français [Adrien-Marie Legendre](https://fr.wikipedia.org/wiki/Adrien-Marie_Legendre) et le mathématicien Allemand [Carl Friedrich Gauss](https://fr.wikipedia.org/wiki/Carl_Friedrich_Gauss) permet de comparer des données expérimentales (généralement entachées d'erreurs de mesure) à un modèle mathématique censé les décrire.\n",
    "Elle repose sur la formulation d'un problème d'optimisation permettant de trouver la meilleure estimation possible des paramètres de ce modèle.\n",
    "\n",
    "Afin de limiter la difficulté de ce TP, nous nous limiterons à la méthode dite des *moindres carrés linéaire*.\n",
    "Etant donné un ensemble de données $(x_i, y_i)$ (où $x_i$ est l'abscisse des points de données et $y_i$ leur ordonnée), on supposera alors que ces données peuvent être décrites par le modèle suivant\n",
    "\n",
    "$$\n",
    "y_i \\simeq a x_i + b\n",
    "$$\n",
    "\n",
    "où $a$ et $b$ sont les paramètres que l'on cherche à déterminer.\n",
    "La figure ci-dessous illustre le jeu de données avec lequel nous travaillerons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26523e4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c591a6e111d41529",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(n=512, σ=0.5, a=1.0, b=0.5):\n",
    "    \"\"\"\n",
    "    Fonction permettant de générer un jeu de données aléatoire.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --> Génère aléatoirement les abscisses des points.\n",
    "    x = npr.normal(loc=0, scale=3, size=n)\n",
    "    \n",
    "    # --> Génère la droite déterministe.\n",
    "    y = a*x + b\n",
    "    \n",
    "    # --> Ajoute du bruit.\n",
    "    y += npr.normal(loc=0, scale=σ, size=n)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# --> Génération des données dont vous aurez besoin.\n",
    "x, y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4b7042",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-601da5c8382dec25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f69752cb3d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax.scatter(x, y, alpha=0.2, label=\"Données\")\n",
    "\n",
    "ax.set(xlim=(-10, 10), ylim=(-10, 10))\n",
    "ax.set(xlabel=\"x\", ylabel=\"y\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfcdd7",
   "metadata": {},
   "source": [
    "En regardant cette figure, une relation linéaire entre $x_i$ et $y_i$ est assez évidente et notre modèle mathématique semble donc plausible.\n",
    "La question à laquelle nous souhaiterons répondre est donc : comment calculer la meilleure estimation possible des paramètres $a$ et $b$ de notre modèle ?\n",
    "\n",
    "### Formulation mathématique\n",
    "\n",
    "Afin de répondre à cette question, il nous est d'abord nécessaire de définir une notion de l'erreur entre les prédictions $\\hat{y}_i$ de notre modèle et nos observations expérimentales $y_i$.\n",
    "Plusieurs définitions ont été proposées pendant la séance de cours.\n",
    "La définition la plus commune est celle de l'[erreur quadratique moyenne](https://fr.wikipedia.org/wiki/Erreur_quadratique_moyenne).\n",
    "Etant données les prédictions de notre modèle $\\hat{y}_i = a x_i + b$ et les observations $y_i$, cette erreur est définie de la façon suivante\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(a, b) = \\dfrac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "où $n$ est le nombre d'observations disponibles.\n",
    "Cette notion de l'erreur faisant intervenir un carré, elle sera toujours positive.\n",
    "De plus, si notre modèle prédit exactement les observations (i.e. $\\hat{y}_i = y_i \\quad \\forall i$), alors cette erreur vaut 0.\n",
    "Dans le cas contraire, elle sera supérieure à 0.\n",
    "On cherche alors à trouver les valeurs de $a$ et $b$ de façon à minimiser cette erreur au maximum.\n",
    "\n",
    "#### Comment minimiser une fonction ?\n",
    "\n",
    "Lorsqu'une fonction (dérivable au moins une fois) atteint son minimum, le gradient de cette fonction est nul.\n",
    "Minimiser une fonction revient donc à trouver les valeurs des paramètres de façon à ce que le gradient soit nul.\n",
    "Une illustration a été donnée en cours.\n",
    "Il nous est donc nécessaire de trouver une expression analytique du gradient de notre fonction objective.\n",
    "\n",
    "Notre modèle étant donné par\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = a x_i + b,\n",
    "$$\n",
    "\n",
    "il est facile de montrer que la dérivée partielle de notre erreur quadratique moyenne $\\mathcal{L}$ par rapport au coefficient directeur $a$ de la droite que l'on cherche à calculer est donnée par\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial \\mathcal{L}}{\\partial a} = -\\dfrac{2}{n} \\sum_{i=1}^n \\left( y_i - a x_i - b \\right) x_i.\n",
    "$$\n",
    "\n",
    "De la même façon, la dérivée partielle de $\\mathcal{L}$ par rapport à $b$ est donnée par\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial \\mathcal{L}}{\\partial b} = -\\dfrac{2}{n} \\sum_{i=1}^n \\left( y_i - ax_i - b \\right).\n",
    "$$\n",
    "\n",
    "A partir d'une estimation initiale des paramètres $a$ et $b$, le gradient de $\\mathcal{L}$ indique la direction dans laquelle notre erreur augmente.\n",
    "Ainsi, si $\\partial_a \\mathcal{L} > 0$, augmenter légèrement la valeur de $a$ aura tendance à augmenter l'erreur de notre modèle (et similairement pour $b$).\n",
    "Afin de minimiser notre fonction, il sera alors nécessaire de diminuer légèrement la valeur de $a$.\n",
    "De même, si $\\partial_a \\mathcal{L} < 0$, diminuer légèrement la valeur de $a$ aura tendance à augmenter l'erreur de notre modèle.\n",
    "Afin de minimiser notre fonction, il sera alors cette fois ci nécessaire d'augmenter légèrement la valeur de $a$.\n",
    "Les mêmes principes s'appliquent pour $b$.\n",
    "\n",
    "A partir de ce constat, il est alors facile de se convaincre que, étant donnée une estimation initiale des paramètres $a_0$ et $b_0$ du modèle, l'algorithme suivant devrait petit à petit converger vers un minimum de la fonction:\n",
    "\n",
    "1. Calcul de $\\mathcal{L}(a_k, b_k)$ et du gradient $\\nabla \\mathcal{L}$.\n",
    "Si la norme du gradient est suffisament petite, alors on s'arrête car l'on est déjà très proche du minimum.\n",
    "Sinon, on passe à l'étape 2.\n",
    "2. Mise à jour des paramètres par la règle suivante\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a_{k+1} & = a_k - \\eta \\dfrac{\\partial \\mathcal{L}}{\\partial a} \\\\\n",
    "b_{k+1} & = b_k - \\eta \\dfrac{\\partial \\mathcal{L}}{\\partial b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "où $\\eta$ est le *pas de descente*.\n",
    "En pratique $\\eta$ ne doit pas être trop grand.\n",
    "3. On retourne ensuite à la première étape.\n",
    "\n",
    "Cet algorithme, connu sous le nom de **descente de gradient**, forme aujourd'hui la base de la plupart des méthodes d'optimisation, notamment celles utilisées en Machine Learning et Deep Learning.\n",
    "\n",
    "### Illustration\n",
    "\n",
    "Les cellules ci-dessous illustrent comment il vous est possible d'implémenter un tel algorithme en `python`.\n",
    "Prenez le temps de bien lire les commentaires et de comparer les expressions avec celles données au dessous afin de bien comprendre ce que fait ce code.\n",
    "Votre objectif sera de ré-écrire ce même code mais de façon plus efficace en utilisant au maximum les fonctions déjà présentes dans **NumPy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016b98c7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-79909f728752f19f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def objectif(x, y, a, b):\n",
    "    \"\"\"\n",
    "    Fonction calculant la valeur de la fonction objective\n",
    "    pour les paramètres courants a et b.\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    \n",
    "    x : Numpy array, shape (n,)\n",
    "        Abscise des points de données.\n",
    "        \n",
    "    y : Numpy array, shape (n,)\n",
    "        Ordonnée des points de données.\n",
    "        \n",
    "    a : float\n",
    "        Cofficient directeur de la droite y = ax + b.\n",
    "        \n",
    "    b : float\n",
    "        Constante de la droite y = ax + b.\n",
    "        \n",
    "    RETURN\n",
    "    ------\n",
    "    \n",
    "    mse : float\n",
    "          Erreur quadratique moyenne calculée à partir\n",
    "          des coefficients a et b du modèle.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --> Nombre de points de données.\n",
    "    n = len(x)\n",
    "    \n",
    "    # --> Calcul de l'erreur quadratique moyenne.\n",
    "    mse = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        mse = mse + (y[i] - (a*x[i] + b))**2\n",
    "        \n",
    "    mse = mse / n\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642db8e",
   "metadata": {},
   "source": [
    "La fonction ci-dessus calcule l'erreur quadratique moyenne de notre modèle (paramètres actuels $a$ et $b$) vis à vis de nos données.\n",
    "La cellule ci-dessous illustre comment tester le temps d'exécution de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56d4e42",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c3dd143d4d6d22c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 µs ± 120 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "objectif(x, y, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db525d7d",
   "metadata": {},
   "source": [
    "Sur mon ordinateur, cette fonction prends de l'ordre de 500 microsecondes pour s'exécuter.\n",
    "Plus tard dans le TP, il vous sera demander de la ré-écrire de façon plus optimisée.\n",
    "En utilisant intelligement la fonction `np.mean` par exemple, il vous sera possible d'augmenter la rapidité d'exécution d'un facteur presque 30 (i.e. 15 microsecondes au lieu de 500). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfd6858",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a326869aee66405",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient(x, y, a, b):\n",
    "    \"\"\"\n",
    "    Fonction calculant le gradient de la fonction objective\n",
    "    (i.e. les dérivées partielles par rapport à a et b).\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    \n",
    "    x : Numpy array, shape (n,)\n",
    "        Abscise des points de données.\n",
    "        \n",
    "    y : Numpy array, shape (n,)\n",
    "        Ordonnée des points de données.\n",
    "        \n",
    "    a : float\n",
    "        Cofficient directeur de la droite y = ax + b.\n",
    "        \n",
    "    b : float\n",
    "        Constante de la droite y = ax + b.\n",
    "        \n",
    "    RETURN\n",
    "    ------\n",
    "    \n",
    "    da : float\n",
    "         Composante du gradient par rapport à la variable a.\n",
    "         \n",
    "    db : float\n",
    "         Composante du gradient par rapport à la variable b.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --> Nombre de points.\n",
    "    n = len(x)\n",
    "    \n",
    "    # --> Calcul de la composante du gradient associée\n",
    "    #     au paramètre a (coefficient directeur).\n",
    "    da = 0.0\n",
    "    for i in range(n):\n",
    "        da = da - (2/n) * (y[i] - a*x[i] - b) * x[i]\n",
    "\n",
    "    # --> Calcul de la composante du gradient associée\n",
    "    #     au paramètre b (constante).\n",
    "    db = 0.0\n",
    "    for i in range(n):\n",
    "        db = db - (2/n) * (y[i] - a*x[i] - b)\n",
    "\n",
    "    return da, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3279951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13 ms ± 191 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gradient(x, y, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856e3884",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4a0f07dc684815b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Pour afficher le caractère η dans Jupyter : \\eta<TABULATION>\n",
    "\n",
    "def optimisation(x, y, η=0.01, tol=1e-8, maxiter=1000, verbose=True):\n",
    "    \"\"\"\n",
    "    Boucle d'optimisation pour estimer les paramètres a et b de notre modèle\n",
    "    à partir des données.\n",
    "\n",
    "    INPUT\n",
    "    -----\n",
    "    \n",
    "    x : Numpy array, shape (n,)\n",
    "        Abscise des points de données.\n",
    "        \n",
    "    y : Numpy array, shape (n,)\n",
    "        Ordonnée des points de données.\n",
    "        \n",
    "    η : flat (optionel)\n",
    "        Pas d'optimisation.\n",
    "        \n",
    "    tol : flat (optionel)\n",
    "          Tolérance pour arrêter le calcul.\n",
    "          \n",
    "    maxiter : int (optionel)\n",
    "              Nombre maximum d'itérations possible avant d'arrêter le calcul.\n",
    "              \n",
    "    verbose : boolean (optionel)\n",
    "              Contrôle l'affichage à l'écran des informations au cours du calcul.\n",
    "    \n",
    "    RETURN\n",
    "    ------\n",
    "    \n",
    "    a : float\n",
    "        Estimation du coefficient directeur de la droite.\n",
    "        \n",
    "    b : float\n",
    "        Estimation de la constante du modèle.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --> Estimation initiale des paramètres.\n",
    "    a, b = 0.0, 0.0\n",
    "    \n",
    "    # --> Descente de gradient.\n",
    "    for i in range(maxiter):\n",
    "        # --> Calcul de la fonction objective.\n",
    "        erreur = objectif(x, y, a, b)\n",
    "        \n",
    "        # --> Calcul du gradient.\n",
    "        da, db = gradient(x, y, a, b)\n",
    "        \n",
    "        # --> Norme du gradient.\n",
    "        residu = da**2 + db**2\n",
    "        \n",
    "        # --> Affichage à l'écran.\n",
    "        if verbose:\n",
    "            print(\"Itération {0} :\".format(i))\n",
    "            print(\"     - Fonction objective : {0}\".format(erreur))\n",
    "            print(\"     - Norme du gradient : {0}\".format(residu))\n",
    "            print()\n",
    "        \n",
    "        # --> Test si la norme du gradient est suffisament petite.\n",
    "        if residu < tol:\n",
    "            break\n",
    "            \n",
    "        # --> Mise à jour des paramètres.\n",
    "        a = a - η*da\n",
    "        b = b - η*db\n",
    "    \n",
    "    # --> Affiche les coefficients obtenus à la fin.\n",
    "    if verbose:\n",
    "        print(\"\\n-------------------------------------\\n\\n\")\n",
    "        print(\"Estimation du coefficient directeur : {0}\".format(a))\n",
    "        print(\"Estimation de la constante : {0}\".format(b))\n",
    "    \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9ae669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 0 :\n",
      "     - Fonction objective : 9.947771784619572\n",
      "     - Norme du gradient : 363.59839924391673\n",
      "\n",
      "Itération 1 :\n",
      "     - Fonction objective : 6.661316443940576\n",
      "     - Norme du gradient : 237.25794676843358\n",
      "\n",
      "Itération 2 :\n",
      "     - Fonction objective : 4.516538119227279\n",
      "     - Norme du gradient : 154.91595468870915\n",
      "\n",
      "Itération 3 :\n",
      "     - Fonction objective : 3.1158551275937465\n",
      "     - Norme du gradient : 101.24591261004198\n",
      "\n",
      "Itération 4 :\n",
      "     - Fonction objective : 2.200179740774782\n",
      "     - Norme du gradient : 66.2603314785631\n",
      "\n",
      "Itération 5 :\n",
      "     - Fonction objective : 1.6006735489758026\n",
      "     - Norme du gradient : 43.45087843614633\n",
      "\n",
      "Itération 6 :\n",
      "     - Fonction objective : 1.2073089972175577\n",
      "     - Norme du gradient : 28.57640188325629\n",
      "\n",
      "Itération 7 :\n",
      "     - Fonction objective : 0.9483826081279424\n",
      "     - Norme du gradient : 18.873152031811046\n",
      "\n",
      "Itération 8 :\n",
      "     - Fonction objective : 0.7771648349010899\n",
      "     - Norme du gradient : 12.540123739343334\n",
      "\n",
      "Itération 9 :\n",
      "     - Fonction objective : 0.6632004757369975\n",
      "     - Norme du gradient : 8.403681859454029\n",
      "\n",
      "Itération 10 :\n",
      "     - Fonction objective : 0.5866396113991263\n",
      "     - Norme du gradient : 5.699015445943207\n",
      "\n",
      "Itération 11 :\n",
      "     - Fonction objective : 0.5345433732943095\n",
      "     - Norme du gradient : 3.9277230900439024\n",
      "\n",
      "Itération 12 :\n",
      "     - Fonction objective : 0.49847660351277745\n",
      "     - Norme du gradient : 2.7650088571162366\n",
      "\n",
      "Itération 13 :\n",
      "     - Fonction objective : 0.47293911395343236\n",
      "     - Norme du gradient : 1.9992068056434\n",
      "\n",
      "Itération 14 :\n",
      "     - Fonction objective : 0.45434341597108563\n",
      "     - Norme du gradient : 1.4923723197657082\n",
      "\n",
      "Itération 15 :\n",
      "     - Fonction objective : 0.440348555934606\n",
      "     - Norme du gradient : 1.1546015613370955\n",
      "\n",
      "Itération 16 :\n",
      "     - Fonction objective : 0.42942600622456706\n",
      "     - Norme du gradient : 0.927296806039628\n",
      "\n",
      "Itération 17 :\n",
      "     - Fonction objective : 0.42057677458689785\n",
      "     - Norme du gradient : 0.7722613357636308\n",
      "\n",
      "Itération 18 :\n",
      "     - Fonction objective : 0.4131470546191167\n",
      "     - Norme du gradient : 0.66459314262996\n",
      "\n",
      "Itération 19 :\n",
      "     - Fonction objective : 0.40670809044481676\n",
      "     - Norme du gradient : 0.5880541166761514\n",
      "\n",
      "Itération 20 :\n",
      "     - Fonction objective : 0.400977886530385\n",
      "     - Norme du gradient : 0.5320523749220688\n",
      "\n",
      "Itération 21 :\n",
      "     - Fonction objective : 0.3957701859227278\n",
      "     - Norme du gradient : 0.4896757893188154\n",
      "\n",
      "Itération 22 :\n",
      "     - Fonction objective : 0.3909612180294308\n",
      "     - Norme du gradient : 0.4564105256037339\n",
      "\n",
      "Itération 23 :\n",
      "     - Fonction objective : 0.38646802602230734\n",
      "     - Norme du gradient : 0.42930596786358083\n",
      "\n",
      "Itération 24 :\n",
      "     - Fonction objective : 0.3822343402179155\n",
      "     - Norme du gradient : 0.40643052946784486\n",
      "\n",
      "Itération 25 :\n",
      "     - Fonction objective : 0.378221368916739\n",
      "     - Norme du gradient : 0.38651701972387786\n",
      "\n",
      "Itération 26 :\n",
      "     - Fonction objective : 0.37440179383003\n",
      "     - Norme du gradient : 0.36873153445218965\n",
      "\n",
      "Itération 27 :\n",
      "     - Fonction objective : 0.3707558539020198\n",
      "     - Norme du gradient : 0.3525228410565789\n",
      "\n",
      "Itération 28 :\n",
      "     - Fonction objective : 0.3672687901591276\n",
      "     - Norme du gradient : 0.3375242180863514\n",
      "\n",
      "Itération 29 :\n",
      "     - Fonction objective : 0.36392917759380655\n",
      "     - Norme du gradient : 0.3234894770958376\n",
      "\n",
      "Itération 30 :\n",
      "     - Fonction objective : 0.3607278352025373\n",
      "     - Norme du gradient : 0.31025125976668977\n",
      "\n",
      "Itération 31 :\n",
      "     - Fonction objective : 0.35765711289220864\n",
      "     - Norme du gradient : 0.29769385109458724\n",
      "\n",
      "Itération 32 :\n",
      "     - Fonction objective : 0.3547104240831419\n",
      "     - Norme du gradient : 0.28573545236635695\n",
      "\n",
      "Itération 33 :\n",
      "     - Fonction objective : 0.351881938526688\n",
      "     - Norme du gradient : 0.2743166190058176\n",
      "\n",
      "Itération 34 :\n",
      "     - Fonction objective : 0.34916637962907104\n",
      "     - Norme du gradient : 0.2633927161467634\n",
      "\n",
      "Itération 35 :\n",
      "     - Fonction objective : 0.34655888997526063\n",
      "     - Norme du gradient : 0.2529289927391559\n",
      "\n",
      "Itération 36 :\n",
      "     - Fonction objective : 0.34405494139013737\n",
      "     - Norme du gradient : 0.24289736239292695\n",
      "\n",
      "Itération 37 :\n",
      "     - Fonction objective : 0.34165027411345744\n",
      "     - Norme du gradient : 0.2332742967757956\n",
      "\n",
      "Itération 38 :\n",
      "     - Fonction objective : 0.33934085503434364\n",
      "     - Norme du gradient : 0.2240394443530023\n",
      "\n",
      "Itération 39 :\n",
      "     - Fonction objective : 0.33712284843000084\n",
      "     - Norme du gradient : 0.2151747221296248\n",
      "\n",
      "Itération 40 :\n",
      "     - Fonction objective : 0.33499259493359457\n",
      "     - Norme du gradient : 0.20666371594613323\n",
      "\n",
      "Itération 41 :\n",
      "     - Fonction objective : 0.3329465959422728\n",
      "     - Norme du gradient : 0.1984912821515612\n",
      "\n",
      "Itération 42 :\n",
      "     - Fonction objective : 0.3309815016447897\n",
      "     - Norme du gradient : 0.19064328080141066\n",
      "\n",
      "Itération 43 :\n",
      "     - Fonction objective : 0.32909410147945817\n",
      "     - Norme du gradient : 0.18310639484911814\n",
      "\n",
      "Itération 44 :\n",
      "     - Fonction objective : 0.32728131624459705\n",
      "     - Norme du gradient : 0.1758680056495518\n",
      "\n",
      "Itération 45 :\n",
      "     - Fonction objective : 0.32554019135188766\n",
      "     - Norme du gradient : 0.16891610542181298\n",
      "\n",
      "Itération 46 :\n",
      "     - Fonction objective : 0.32386789088795737\n",
      "     - Norme du gradient : 0.1622392340497834\n",
      "\n",
      "Itération 47 :\n",
      "     - Fonction objective : 0.3222616922635938\n",
      "     - Norme du gradient : 0.15582643198559712\n",
      "\n",
      "Itération 48 :\n",
      "     - Fonction objective : 0.3207189813044169\n",
      "     - Norme du gradient : 0.14966720388023527\n",
      "\n",
      "Itération 49 :\n",
      "     - Fonction objective : 0.3192372476854564\n",
      "     - Norme du gradient : 0.1437514894288862\n",
      "\n",
      "Itération 50 :\n",
      "     - Fonction objective : 0.31781408064383215\n",
      "     - Norme du gradient : 0.13806963913336742\n",
      "\n",
      "Itération 51 :\n",
      "     - Fonction objective : 0.3164471649245267\n",
      "     - Norme du gradient : 0.132612393475813\n",
      "\n",
      "Itération 52 :\n",
      "     - Fonction objective : 0.31513427692787443\n",
      "     - Norme du gradient : 0.12737086451419358\n",
      "\n",
      "Itération 53 :\n",
      "     - Fonction objective : 0.31387328103634116\n",
      "     - Norme du gradient : 0.12233651924703429\n",
      "\n",
      "Itération 54 :\n",
      "     - Fonction objective : 0.3126621261040934\n",
      "     - Norme du gradient : 0.11750116431450511\n",
      "\n",
      "Itération 55 :\n",
      "     - Fonction objective : 0.3114988420967993\n",
      "     - Norme du gradient : 0.11285693174658187\n",
      "\n",
      "Itération 56 :\n",
      "     - Fonction objective : 0.3103815368717191\n",
      "     - Norme du gradient : 0.10839626556278105\n",
      "\n",
      "Itération 57 :\n",
      "     - Fonction objective : 0.3093083930899227\n",
      "     - Norme du gradient : 0.1041119090893974\n",
      "\n",
      "Itération 58 :\n",
      "     - Fonction objective : 0.30827766525374606\n",
      "     - Norme du gradient : 0.09999689290043452\n",
      "\n",
      "Itération 59 :\n",
      "     - Fonction objective : 0.30728767686339425\n",
      "     - Norme du gradient : 0.0960445233149469\n",
      "\n",
      "Itération 60 :\n",
      "     - Fonction objective : 0.3063368176872875\n",
      "     - Norme du gradient : 0.09224837140099858\n",
      "\n",
      "Itération 61 :\n",
      "     - Fonction objective : 0.3054235411411717\n",
      "     - Norme du gradient : 0.0886022624481197\n",
      "\n",
      "Itération 62 :\n",
      "     - Fonction objective : 0.3045463617713955\n",
      "     - Norme du gradient : 0.0851002658779318\n",
      "\n",
      "Itération 63 :\n",
      "     - Fonction objective : 0.30370385283802454\n",
      "     - Norme du gradient : 0.08173668556794474\n",
      "\n",
      "Itération 64 :\n",
      "     - Fonction objective : 0.3028946439937415\n",
      "     - Norme du gradient : 0.07850605056717293\n",
      "\n",
      "Itération 65 :\n",
      "     - Fonction objective : 0.30211741905462797\n",
      "     - Norme du gradient : 0.07540310618482599\n",
      "\n",
      "Itération 66 :\n",
      "     - Fonction objective : 0.30137091385917436\n",
      "     - Norme du gradient : 0.07242280543520223\n",
      "\n",
      "Itération 67 :\n",
      "     - Fonction objective : 0.3006539142119698\n",
      "     - Norme du gradient : 0.06956030082330829\n",
      "\n",
      "Itération 68 :\n",
      "     - Fonction objective : 0.29996525390871603\n",
      "     - Norme du gradient : 0.06681093645684956\n",
      "\n",
      "Itération 69 :\n",
      "     - Fonction objective : 0.29930381283933066\n",
      "     - Norme du gradient : 0.0641702404710882\n",
      "\n",
      "Itération 70 :\n",
      "     - Fonction objective : 0.2986685151660401\n",
      "     - Norme du gradient : 0.06163391775383069\n",
      "\n",
      "Itération 71 :\n",
      "     - Fonction objective : 0.2980583275735017\n",
      "     - Norme du gradient : 0.05919784295842413\n",
      "\n",
      "Itération 72 :\n",
      "     - Fonction objective : 0.2974722575880895\n",
      "     - Norme du gradient : 0.05685805379321984\n",
      "\n",
      "Itération 73 :\n",
      "     - Fonction objective : 0.2969093519636251\n",
      "     - Norme du gradient : 0.054610744576466926\n",
      "\n",
      "Itération 74 :\n",
      "     - Fonction objective : 0.29636869513090314\n",
      "     - Norme du gradient : 0.05245226004608072\n",
      "\n",
      "Itération 75 :\n",
      "     - Fonction objective : 0.29584940770851653\n",
      "     - Norme du gradient : 0.05037908941416004\n",
      "\n",
      "Itération 76 :\n",
      "     - Fonction objective : 0.2953506450725278\n",
      "     - Norme du gradient : 0.04838786065655629\n",
      "\n",
      "Itération 77 :\n",
      "     - Fonction objective : 0.2948715959826847\n",
      "     - Norme du gradient : 0.04647533502818365\n",
      "\n",
      "Itération 78 :\n",
      "     - Fonction objective : 0.2944114812629318\n",
      "     - Norme du gradient : 0.0446384017951311\n",
      "\n",
      "Itération 79 :\n",
      "     - Fonction objective : 0.29396955253407464\n",
      "     - Norme du gradient : 0.04287407317500521\n",
      "\n",
      "Itération 80 :\n",
      "     - Fonction objective : 0.29354509099653786\n",
      "     - Norme du gradient : 0.041179479477264934\n",
      "\n",
      "Itération 81 :\n",
      "     - Fonction objective : 0.29313740626122975\n",
      "     - Norme du gradient : 0.03955186443563937\n",
      "\n",
      "Itération 82 :\n",
      "     - Fonction objective : 0.2927458352266258\n",
      "     - Norme du gradient : 0.03798858072503693\n",
      "\n",
      "Itération 83 :\n",
      "     - Fonction objective : 0.29236974100022434\n",
      "     - Norme du gradient : 0.03648708565564972\n",
      "\n",
      "Itération 84 :\n",
      "     - Fonction objective : 0.29200851186264193\n",
      "     - Norme du gradient : 0.03504493703725136\n",
      "\n",
      "Itération 85 :\n",
      "     - Fonction objective : 0.29166156027264445\n",
      "     - Norme du gradient : 0.03365978920695758\n",
      "\n",
      "Itération 86 :\n",
      "     - Fonction objective : 0.2913283219115101\n",
      "     - Norme du gradient : 0.03232938921399077\n",
      "\n",
      "Itération 87 :\n",
      "     - Fonction objective : 0.29100825476516246\n",
      "     - Norme du gradient : 0.031051573155242568\n",
      "\n",
      "Itération 88 :\n",
      "     - Fonction objective : 0.29070083824257864\n",
      "     - Norme du gradient : 0.029824262655671504\n",
      "\n",
      "Itération 89 :\n",
      "     - Fonction objective : 0.2904055723290493\n",
      "     - Norme du gradient : 0.02864546148781436\n",
      "\n",
      "Itération 90 :\n",
      "     - Fonction objective : 0.29012197677289625\n",
      "     - Norme du gradient : 0.027513252324910746\n",
      "\n",
      "Itération 91 :\n",
      "     - Fonction objective : 0.2898495903043467\n",
      "     - Norme du gradient : 0.026425793622359615\n",
      "\n",
      "Itération 92 :\n",
      "     - Fonction objective : 0.2895879698852687\n",
      "     - Norme du gradient : 0.02538131662243686\n",
      "\n",
      "Itération 93 :\n",
      "     - Fonction objective : 0.28933668998857426\n",
      "     - Norme du gradient : 0.02437812247740097\n",
      "\n",
      "Itération 94 :\n",
      "     - Fonction objective : 0.28909534190609065\n",
      "     - Norme du gradient : 0.023414579486306864\n",
      "\n",
      "Itération 95 :\n",
      "     - Fonction objective : 0.2888635330837986\n",
      "     - Norme du gradient : 0.022489120441035404\n",
      "\n",
      "Itération 96 :\n",
      "     - Fonction objective : 0.2886408864833392\n",
      "     - Norme du gradient : 0.021600240077221052\n",
      "\n",
      "Itération 97 :\n",
      "     - Fonction objective : 0.2884270399687579\n",
      "     - Norme du gradient : 0.020746492625929695\n",
      "\n",
      "Itération 98 :\n",
      "     - Fonction objective : 0.2882216457174912\n",
      "     - Norme du gradient : 0.019926489462108378\n",
      "\n",
      "Itération 99 :\n",
      "     - Fonction objective : 0.2880243696546296\n",
      "     - Norme du gradient : 0.019138896845978245\n",
      "\n",
      "Itération 100 :\n",
      "     - Fonction objective : 0.28783489090954173\n",
      "     - Norme du gradient : 0.01838243375369944\n",
      "\n",
      "Itération 101 :\n",
      "     - Fonction objective : 0.2876529012939775\n",
      "     - Norme du gradient : 0.017655869793778457\n",
      "\n",
      "Itération 102 :\n",
      "     - Fonction objective : 0.28747810480079933\n",
      "     - Norme du gradient : 0.016958023205829422\n",
      "\n",
      "Itération 103 :\n",
      "     - Fonction objective : 0.2873102171225248\n",
      "     - Norme du gradient : 0.016287758938434486\n",
      "\n",
      "Itération 104 :\n",
      "     - Fonction objective : 0.2871489651888946\n",
      "     - Norme du gradient : 0.015643986802975737\n",
      "\n",
      "Itération 105 :\n",
      "     - Fonction objective : 0.28699408672272947\n",
      "     - Norme du gradient : 0.015025659700437767\n",
      "\n",
      "Itération 106 :\n",
      "     - Fonction objective : 0.28684532981332767\n",
      "     - Norme du gradient : 0.014431771918294768\n",
      "\n",
      "Itération 107 :\n",
      "     - Fonction objective : 0.2867024525067365\n",
      "     - Norme du gradient : 0.013861357494713742\n",
      "\n",
      "Itération 108 :\n",
      "     - Fonction objective : 0.2865652224122095\n",
      "     - Norme du gradient : 0.013313488647412037\n",
      "\n",
      "Itération 109 :\n",
      "     - Fonction objective : 0.2864334163242221\n",
      "     - Norme du gradient : 0.01278727426461408\n",
      "\n",
      "Itération 110 :\n",
      "     - Fonction objective : 0.28630681985942824\n",
      "     - Norme du gradient : 0.012281858455653327\n",
      "\n",
      "Itération 111 :\n",
      "     - Fonction objective : 0.28618522710796235\n",
      "     - Norme du gradient : 0.011796419158860899\n",
      "\n",
      "Itération 112 :\n",
      "     - Fonction objective : 0.28606844029852657\n",
      "     - Norme du gradient : 0.011330166804478022\n",
      "\n",
      "Itération 113 :\n",
      "     - Fonction objective : 0.28595626947671615\n",
      "     - Norme du gradient : 0.01088234303041598\n",
      "\n",
      "Itération 114 :\n",
      "     - Fonction objective : 0.28584853219605627\n",
      "     - Norme du gradient : 0.010452219448776187\n",
      "\n",
      "Itération 115 :\n",
      "     - Fonction objective : 0.28574505322125\n",
      "     - Norme du gradient : 0.010039096461122917\n",
      "\n",
      "Itération 116 :\n",
      "     - Fonction objective : 0.28564566424316096\n",
      "     - Norme du gradient : 0.009642302120582789\n",
      "\n",
      "Itération 117 :\n",
      "     - Fonction objective : 0.2855502036050544\n",
      "     - Norme du gradient : 0.009261191038919037\n",
      "\n",
      "Itération 118 :\n",
      "     - Fonction objective : 0.285458516039664\n",
      "     - Norme du gradient : 0.008895143336804096\n",
      "\n",
      "Itération 119 :\n",
      "     - Fonction objective : 0.28537045241664516\n",
      "     - Norme du gradient : 0.008543563635582405\n",
      "\n",
      "Itération 120 :\n",
      "     - Fonction objective : 0.28528586950001805\n",
      "     - Norme du gradient : 0.008205880088883559\n",
      "\n",
      "Itération 121 :\n",
      "     - Fonction objective : 0.2852046297151913\n",
      "     - Norme du gradient : 0.007881543452510997\n",
      "\n",
      "Itération 122 :\n",
      "     - Fonction objective : 0.2851266009251961\n",
      "     - Norme du gradient : 0.00757002619109325\n",
      "\n",
      "Itération 123 :\n",
      "     - Fonction objective : 0.28505165621576384\n",
      "     - Norme du gradient : 0.007270821620044587\n",
      "\n",
      "Itération 124 :\n",
      "     - Fonction objective : 0.2849796736889019\n",
      "     - Norme du gradient : 0.006983443081439744\n",
      "\n",
      "Itération 125 :\n",
      "     - Fonction objective : 0.2849105362646233\n",
      "     - Norme du gradient : 0.006707423152462012\n",
      "\n",
      "Itération 126 :\n",
      "     - Fonction objective : 0.2848441314905169\n",
      "     - Norme du gradient : 0.006442312885137503\n",
      "\n",
      "Itération 127 :\n",
      "     - Fonction objective : 0.2847803513588422\n",
      "     - Norme du gradient : 0.006187681076118512\n",
      "\n",
      "Itération 128 :\n",
      "     - Fonction objective : 0.28471909213085506\n",
      "     - Norme du gradient : 0.005943113565329154\n",
      "\n",
      "Itération 129 :\n",
      "     - Fonction objective : 0.2846602541680747\n",
      "     - Norme du gradient : 0.0057082125623312985\n",
      "\n",
      "Itération 130 :\n",
      "     - Fonction objective : 0.2846037417702227\n",
      "     - Norme du gradient : 0.005482595999316458\n",
      "\n",
      "Itération 131 :\n",
      "     - Fonction objective : 0.2845494630195648\n",
      "     - Norme du gradient : 0.0052658969096701265\n",
      "\n",
      "Itération 132 :\n",
      "     - Fonction objective : 0.2844973296314058\n",
      "     - Norme du gradient : 0.005057762831098729\n",
      "\n",
      "Itération 133 :\n",
      "     - Fonction objective : 0.2844472568104951\n",
      "     - Norme du gradient : 0.004857855232347587\n",
      "\n",
      "Itération 134 :\n",
      "     - Fonction objective : 0.2843991631131074\n",
      "     - Norme du gradient : 0.004665848962577859\n",
      "\n",
      "Itération 135 :\n",
      "     - Fonction objective : 0.284352970314572\n",
      "     - Norme du gradient : 0.004481431722506913\n",
      "\n",
      "Itération 136 :\n",
      "     - Fonction objective : 0.2843086032820405\n",
      "     - Norme du gradient : 0.00430430355645192\n",
      "\n",
      "Itération 137 :\n",
      "     - Fonction objective : 0.28426598985228446\n",
      "     - Norme du gradient : 0.004134176364450045\n",
      "\n",
      "Itération 138 :\n",
      "     - Fonction objective : 0.284225060714319\n",
      "     - Norme du gradient : 0.003970773433662275\n",
      "\n",
      "Itération 139 :\n",
      "     - Fonction objective : 0.2841857492966713\n",
      "     - Norme du gradient : 0.0038138289882984995\n",
      "\n",
      "Itération 140 :\n",
      "     - Fonction objective : 0.2841479916590968\n",
      "     - Norme du gradient : 0.0036630877573316156\n",
      "\n",
      "Itération 141 :\n",
      "     - Fonction objective : 0.2841117263885853\n",
      "     - Norme du gradient : 0.0035183045592978345\n",
      "\n",
      "Itération 142 :\n",
      "     - Fonction objective : 0.28407689449946966\n",
      "     - Norme du gradient : 0.0033792439035075163\n",
      "\n",
      "Itération 143 :\n",
      "     - Fonction objective : 0.28404343933748544\n",
      "     - Norme du gradient : 0.0032456796070183553\n",
      "\n",
      "Itération 144 :\n",
      "     - Fonction objective : 0.2840113064876225\n",
      "     - Norme du gradient : 0.003117394426747526\n",
      "\n",
      "Itération 145 :\n",
      "     - Fonction objective : 0.2839804436856187\n",
      "     - Norme du gradient : 0.0029941797061244853\n",
      "\n",
      "Itération 146 :\n",
      "     - Fonction objective : 0.28395080073295276\n",
      "     - Norme du gradient : 0.0028758350357100428\n",
      "\n",
      "Itération 147 :\n",
      "     - Fonction objective : 0.28392232941519446\n",
      "     - Norme du gradient : 0.0027621679272291392\n",
      "\n",
      "Itération 148 :\n",
      "     - Fonction objective : 0.28389498342358394\n",
      "     - Norme du gradient : 0.0026529935004875904\n",
      "\n",
      "Itération 149 :\n",
      "     - Fonction objective : 0.2838687182797129\n",
      "     - Norme du gradient : 0.0025481341826635285\n",
      "\n",
      "Itération 150 :\n",
      "     - Fonction objective : 0.2838434912631752\n",
      "     - Norme du gradient : 0.002447419419484058\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 151 :\n",
      "     - Fonction objective : 0.2838192613420861\n",
      "     - Norme du gradient : 0.0023506853978178628\n",
      "\n",
      "Itération 152 :\n",
      "     - Fonction objective : 0.2837959891063424\n",
      "     - Norme du gradient : 0.002257774779232165\n",
      "\n",
      "Itération 153 :\n",
      "     - Fonction objective : 0.2837736367035207\n",
      "     - Norme du gradient : 0.0021685364440808988\n",
      "\n",
      "Itération 154 :\n",
      "     - Fonction objective : 0.28375216777731166\n",
      "     - Norme du gradient : 0.0020828252457077492\n",
      "\n",
      "Itération 155 :\n",
      "     - Fonction objective : 0.2837315474083864\n",
      "     - Norme du gradient : 0.002000501774364327\n",
      "\n",
      "Itération 156 :\n",
      "     - Fonction objective : 0.2837117420575971\n",
      "     - Norme du gradient : 0.0019214321304593925\n",
      "\n",
      "Itération 157 :\n",
      "     - Fonction objective : 0.2836927195114297\n",
      "     - Norme du gradient : 0.0018454877067703905\n",
      "\n",
      "Itération 158 :\n",
      "     - Fonction objective : 0.2836744488296044\n",
      "     - Norme du gradient : 0.001772544979263125\n",
      "\n",
      "Itération 159 :\n",
      "     - Fonction objective : 0.2836569002947547\n",
      "     - Norme du gradient : 0.0017024853061791722\n",
      "\n",
      "Itération 160 :\n",
      "     - Fonction objective : 0.2836400453640897\n",
      "     - Norme du gradient : 0.0016351947350644503\n",
      "\n",
      "Itération 161 :\n",
      "     - Fonction objective : 0.283623856622969\n",
      "     - Norme du gradient : 0.0015705638174248683\n",
      "\n",
      "Itération 162 :\n",
      "     - Fonction objective : 0.28360830774031415\n",
      "     - Norme du gradient : 0.0015084874307077266\n",
      "\n",
      "Itération 163 :\n",
      "     - Fonction objective : 0.283593373425779\n",
      "     - Norme du gradient : 0.0014488646073193162\n",
      "\n",
      "Itération 164 :\n",
      "     - Fonction objective : 0.2835790293886168\n",
      "     - Norme du gradient : 0.001391598370400527\n",
      "\n",
      "Itération 165 :\n",
      "     - Fonction objective : 0.2835652522981704\n",
      "     - Norme du gradient : 0.0013365955760934714\n",
      "\n",
      "Itération 166 :\n",
      "     - Fonction objective : 0.2835520197459246\n",
      "     - Norme du gradient : 0.0012837667620424445\n",
      "\n",
      "Itération 167 :\n",
      "     - Fonction objective : 0.28353931020905776\n",
      "     - Norme du gradient : 0.0012330260018829425\n",
      "\n",
      "Itération 168 :\n",
      "     - Fonction objective : 0.28352710301543604\n",
      "     - Norme du gradient : 0.0011842907654818727\n",
      "\n",
      "Itération 169 :\n",
      "     - Fonction objective : 0.2835153783099907\n",
      "     - Norme du gradient : 0.0011374817847018823\n",
      "\n",
      "Itération 170 :\n",
      "     - Fonction objective : 0.2835041170224224\n",
      "     - Norme du gradient : 0.001092522924471274\n",
      "\n",
      "Itération 171 :\n",
      "     - Fonction objective : 0.2834933008361826\n",
      "     - Norme du gradient : 0.0010493410589498737\n",
      "\n",
      "Itération 172 :\n",
      "     - Fonction objective : 0.2834829121586838\n",
      "     - Norme du gradient : 0.0010078659525894413\n",
      "\n",
      "Itération 173 :\n",
      "     - Fonction objective : 0.2834729340926831\n",
      "     - Norme du gradient : 0.0009680301458951495\n",
      "\n",
      "Itération 174 :\n",
      "     - Fonction objective : 0.2834633504087992\n",
      "     - Norme du gradient : 0.0009297688457023568\n",
      "\n",
      "Itération 175 :\n",
      "     - Fonction objective : 0.2834541455191171\n",
      "     - Norme du gradient : 0.0008930198197901166\n",
      "\n",
      "Itération 176 :\n",
      "     - Fonction objective : 0.28344530445183125\n",
      "     - Norme du gradient : 0.0008577232956601708\n",
      "\n",
      "Itération 177 :\n",
      "     - Fonction objective : 0.2834368128268956\n",
      "     - Norme du gradient : 0.000823821863316586\n",
      "\n",
      "Itération 178 :\n",
      "     - Fonction objective : 0.28342865683263446\n",
      "     - Norme du gradient : 0.0007912603818881448\n",
      "\n",
      "Itération 179 :\n",
      "     - Fonction objective : 0.28342082320327733\n",
      "     - Norme du gradient : 0.0007599858899413069\n",
      "\n",
      "Itération 180 :\n",
      "     - Fonction objective : 0.2834132991973814\n",
      "     - Norme du gradient : 0.0007299475193382468\n",
      "\n",
      "Itération 181 :\n",
      "     - Fonction objective : 0.28340607257710876\n",
      "     - Norme du gradient : 0.0007010964124994573\n",
      "\n",
      "Itération 182 :\n",
      "     - Fonction objective : 0.28339913158832064\n",
      "     - Norme du gradient : 0.0006733856429366679\n",
      "\n",
      "Itération 183 :\n",
      "     - Fonction objective : 0.2833924649414596\n",
      "     - Norme du gradient : 0.0006467701389266228\n",
      "\n",
      "Itération 184 :\n",
      "     - Fonction objective : 0.2833860617931866\n",
      "     - Norme du gradient : 0.0006212066102016748\n",
      "\n",
      "Itération 185 :\n",
      "     - Fonction objective : 0.283379911728745\n",
      "     - Norme du gradient : 0.0005966534775379196\n",
      "\n",
      "Itération 186 :\n",
      "     - Fonction objective : 0.2833740047450205\n",
      "     - Norme du gradient : 0.0005730708051263716\n",
      "\n",
      "Itération 187 :\n",
      "     - Fonction objective : 0.2833683312342701\n",
      "     - Norme du gradient : 0.0005504202356171019\n",
      "\n",
      "Itération 188 :\n",
      "     - Fonction objective : 0.28336288196849696\n",
      "     - Norme du gradient : 0.0005286649277308407\n",
      "\n",
      "Itération 189 :\n",
      "     - Fonction objective : 0.28335764808444036\n",
      "     - Norme du gradient : 0.0005077694963363928\n",
      "\n",
      "Itération 190 :\n",
      "     - Fonction objective : 0.28335262106915543\n",
      "     - Norme du gradient : 0.00048769995489653307\n",
      "\n",
      "Itération 191 :\n",
      "     - Fonction objective : 0.2833477927461773\n",
      "     - Norme du gradient : 0.000468423660188733\n",
      "\n",
      "Itération 192 :\n",
      "     - Fonction objective : 0.2833431552622083\n",
      "     - Norme du gradient : 0.0004499092592107378\n",
      "\n",
      "Itération 193 :\n",
      "     - Fonction objective : 0.28333870107435616\n",
      "     - Norme du gradient : 0.00043212663818475446\n",
      "\n",
      "Itération 194 :\n",
      "     - Fonction objective : 0.2833344229378583\n",
      "     - Norme du gradient : 0.00041504687357721406\n",
      "\n",
      "Itération 195 :\n",
      "     - Fonction objective : 0.2833303138943025\n",
      "     - Norme du gradient : 0.0003986421850544891\n",
      "\n",
      "Itération 196 :\n",
      "     - Fonction objective : 0.28332636726030475\n",
      "     - Norme du gradient : 0.00038288589029800894\n",
      "\n",
      "Itération 197 :\n",
      "     - Fonction objective : 0.28332257661664373\n",
      "     - Norme du gradient : 0.0003677523616053332\n",
      "\n",
      "Itération 198 :\n",
      "     - Fonction objective : 0.2833189357978162\n",
      "     - Norme du gradient : 0.0003532169842065456\n",
      "\n",
      "Itération 199 :\n",
      "     - Fonction objective : 0.28331543888200866\n",
      "     - Norme du gradient : 0.0003392561162281799\n",
      "\n",
      "Itération 200 :\n",
      "     - Fonction objective : 0.2833120801814697\n",
      "     - Norme du gradient : 0.00032584705023959437\n",
      "\n",
      "Itération 201 :\n",
      "     - Fonction objective : 0.2833088542332515\n",
      "     - Norme du gradient : 0.0003129679763192006\n",
      "\n",
      "Itération 202 :\n",
      "     - Fonction objective : 0.2833057557903325\n",
      "     - Norme du gradient : 0.00030059794658050126\n",
      "\n",
      "Itération 203 :\n",
      "     - Fonction objective : 0.2833027798130784\n",
      "     - Norme du gradient : 0.00028871684110024046\n",
      "\n",
      "Itération 204 :\n",
      "     - Fonction objective : 0.2832999214610434\n",
      "     - Norme du gradient : 0.00027730533519322256\n",
      "\n",
      "Itération 205 :\n",
      "     - Fonction objective : 0.2832971760851032\n",
      "     - Norme du gradient : 0.0002663448679806256\n",
      "\n",
      "Itération 206 :\n",
      "     - Fonction objective : 0.28329453921988856\n",
      "     - Norme du gradient : 0.0002558176122005976\n",
      "\n",
      "Itération 207 :\n",
      "     - Fonction objective : 0.28329200657652254\n",
      "     - Norme du gradient : 0.0002457064452121371\n",
      "\n",
      "Itération 208 :\n",
      "     - Fonction objective : 0.28328957403564653\n",
      "     - Norme du gradient : 0.00023599492114500633\n",
      "\n",
      "Itération 209 :\n",
      "     - Fonction objective : 0.2832872376407189\n",
      "     - Norme du gradient : 0.00022666724415044973\n",
      "\n",
      "Itération 210 :\n",
      "     - Fonction objective : 0.2832849935915811\n",
      "     - Norme du gradient : 0.00021770824270912967\n",
      "\n",
      "Itération 211 :\n",
      "     - Fonction objective : 0.2832828382382736\n",
      "     - Norme du gradient : 0.00020910334495459032\n",
      "\n",
      "Itération 212 :\n",
      "     - Fonction objective : 0.28328076807510183\n",
      "     - Norme du gradient : 0.00020083855497201713\n",
      "\n",
      "Itération 213 :\n",
      "     - Fonction objective : 0.28327877973493415\n",
      "     - Norme du gradient : 0.0001929004300338035\n",
      "\n",
      "Itération 214 :\n",
      "     - Fonction objective : 0.2832768699837242\n",
      "     - Norme du gradient : 0.000185276058734893\n",
      "\n",
      "Itération 215 :\n",
      "     - Fonction objective : 0.28327503571525037\n",
      "     - Norme du gradient : 0.0001779530399922899\n",
      "\n",
      "Itération 216 :\n",
      "     - Fonction objective : 0.2832732739460651\n",
      "     - Norme du gradient : 0.0001709194628746397\n",
      "\n",
      "Itération 217 :\n",
      "     - Fonction objective : 0.283271581810641\n",
      "     - Norme du gradient : 0.00016416388722901738\n",
      "\n",
      "Itération 218 :\n",
      "     - Fonction objective : 0.2832699565567095\n",
      "     - Norme du gradient : 0.00015767532507347034\n",
      "\n",
      "Itération 219 :\n",
      "     - Fonction objective : 0.28326839554078653\n",
      "     - Norme du gradient : 0.00015144322272499065\n",
      "\n",
      "Itération 220 :\n",
      "     - Fonction objective : 0.2832668962238707\n",
      "     - Norme du gradient : 0.00014545744363389927\n",
      "\n",
      "Itération 221 :\n",
      "     - Fonction objective : 0.2832654561673142\n",
      "     - Norme du gradient : 0.00013970825189668482\n",
      "\n",
      "Itération 222 :\n",
      "     - Fonction objective : 0.28326407302885737\n",
      "     - Norme du gradient : 0.00013418629642050935\n",
      "\n",
      "Itération 223 :\n",
      "     - Fonction objective : 0.2832627445588172\n",
      "     - Norme du gradient : 0.00012888259571358922\n",
      "\n",
      "Itération 224 :\n",
      "     - Fonction objective : 0.2832614685964311\n",
      "     - Norme du gradient : 0.00012378852327676028\n",
      "\n",
      "Itération 225 :\n",
      "     - Fonction objective : 0.28326024306633724\n",
      "     - Norme du gradient : 0.00011889579357242187\n",
      "\n",
      "Itération 226 :\n",
      "     - Fonction objective : 0.28325906597520434\n",
      "     - Norme du gradient : 0.00011419644854806942\n",
      "\n",
      "Itération 227 :\n",
      "     - Fonction objective : 0.2832579354084879\n",
      "     - Norme du gradient : 0.00010968284469247029\n",
      "\n",
      "Itération 228 :\n",
      "     - Fonction objective : 0.2832568495273147\n",
      "     - Norme du gradient : 0.00010534764060345396\n",
      "\n",
      "Itération 229 :\n",
      "     - Fonction objective : 0.2832558065654919\n",
      "     - Norme du gradient : 0.00010118378504707162\n",
      "\n",
      "Itération 230 :\n",
      "     - Fonction objective : 0.28325480482663634\n",
      "     - Norme du gradient : 9.718450548873782e-05\n",
      "\n",
      "Itération 231 :\n",
      "     - Fonction objective : 0.2832538426814154\n",
      "     - Norme du gradient : 9.334329707765478e-05\n",
      "\n",
      "Itération 232 :\n",
      "     - Fonction objective : 0.283252918564893\n",
      "     - Norme du gradient : 8.965391206664139e-05\n",
      "\n",
      "Itération 233 :\n",
      "     - Fonction objective : 0.2832520309739891\n",
      "     - Norme du gradient : 8.611034965013252e-05\n",
      "\n",
      "Itération 234 :\n",
      "     - Fonction objective : 0.28325117846503195\n",
      "     - Norme du gradient : 8.270684620384081e-05\n",
      "\n",
      "Itération 235 :\n",
      "     - Fonction objective : 0.283250359651411\n",
      "     - Norme du gradient : 7.943786591017625e-05\n",
      "\n",
      "Itération 236 :\n",
      "     - Fonction objective : 0.28324957320132127\n",
      "     - Norme du gradient : 7.629809175422404e-05\n",
      "\n",
      "Itération 237 :\n",
      "     - Fonction objective : 0.28324881783559663\n",
      "     - Norme du gradient : 7.32824168755803e-05\n",
      "\n",
      "Itération 238 :\n",
      "     - Fonction objective : 0.2832480923256314\n",
      "     - Norme du gradient : 7.038593626201521e-05\n",
      "\n",
      "Itération 239 :\n",
      "     - Fonction objective : 0.283247395491379\n",
      "     - Norme du gradient : 6.760393877145026e-05\n",
      "\n",
      "Itération 240 :\n",
      "     - Fonction objective : 0.2832467261994348\n",
      "     - Norme du gradient : 6.493189946924742e-05\n",
      "\n",
      "Itération 241 :\n",
      "     - Fonction objective : 0.2832460833611918\n",
      "     - Norme du gradient : 6.23654722683842e-05\n",
      "\n",
      "Itération 242 :\n",
      "     - Fonction objective : 0.28324546593106914\n",
      "     - Norme du gradient : 5.990048286051814e-05\n",
      "\n",
      "Itération 243 :\n",
      "     - Fonction objective : 0.2832448729048142\n",
      "     - Norme du gradient : 5.753292192645194e-05\n",
      "\n",
      "Itération 244 :\n",
      "     - Fonction objective : 0.2832443033178661\n",
      "     - Norme du gradient : 5.5258938614949644e-05\n",
      "\n",
      "Itération 245 :\n",
      "     - Fonction objective : 0.2832437562437881\n",
      "     - Norme du gradient : 5.307483427930704e-05\n",
      "\n",
      "Itération 246 :\n",
      "     - Fonction objective : 0.28324323079276137\n",
      "     - Norme du gradient : 5.097705646148371e-05\n",
      "\n",
      "Itération 247 :\n",
      "     - Fonction objective : 0.28324272611013684\n",
      "     - Norme du gradient : 4.89621931140047e-05\n",
      "\n",
      "Itération 248 :\n",
      "     - Fonction objective : 0.28324224137504556\n",
      "     - Norme du gradient : 4.70269670502545e-05\n",
      "\n",
      "Itération 249 :\n",
      "     - Fonction objective : 0.28324177579906334\n",
      "     - Norme du gradient : 4.5168230614104654e-05\n",
      "\n",
      "Itération 250 :\n",
      "     - Fonction objective : 0.2832413286249277\n",
      "     - Norme du gradient : 4.33829605602421e-05\n",
      "\n",
      "Itération 251 :\n",
      "     - Fonction objective : 0.2832408991253074\n",
      "     - Norme du gradient : 4.1668253136833795e-05\n",
      "\n",
      "Itération 252 :\n",
      "     - Fonction objective : 0.2832404866016193\n",
      "     - Norme du gradient : 4.002131936257435e-05\n",
      "\n",
      "Itération 253 :\n",
      "     - Fonction objective : 0.2832400903828909\n",
      "     - Norme du gradient : 3.843948049036799e-05\n",
      "\n",
      "Itération 254 :\n",
      "     - Fonction objective : 0.2832397098246707\n",
      "     - Norme du gradient : 3.692016365035715e-05\n",
      "\n",
      "Itération 255 :\n",
      "     - Fonction objective : 0.28323934430797787\n",
      "     - Norme du gradient : 3.546089766511581e-05\n",
      "\n",
      "Itération 256 :\n",
      "     - Fonction objective : 0.2832389932382976\n",
      "     - Norme du gradient : 3.405930903027384e-05\n",
      "\n",
      "Itération 257 :\n",
      "     - Fonction objective : 0.2832386560446143\n",
      "     - Norme du gradient : 3.2713118053997354e-05\n",
      "\n",
      "Itération 258 :\n",
      "     - Fonction objective : 0.2832383321784787\n",
      "     - Norme du gradient : 3.1420135149060346e-05\n",
      "\n",
      "Itération 259 :\n",
      "     - Fonction objective : 0.2832380211131218\n",
      "     - Norme du gradient : 3.0178257271460407e-05\n",
      "\n",
      "Itération 260 :\n",
      "     - Fonction objective : 0.28323772234259403\n",
      "     - Norme du gradient : 2.8985464499814336e-05\n",
      "\n",
      "Itération 261 :\n",
      "     - Fonction objective : 0.28323743538094287\n",
      "     - Norme du gradient : 2.7839816749940397e-05\n",
      "\n",
      "Itération 262 :\n",
      "     - Fonction objective : 0.28323715976142394\n",
      "     - Norme du gradient : 2.6739450619301313e-05\n",
      "\n",
      "Itération 263 :\n",
      "     - Fonction objective : 0.28323689503574023\n",
      "     - Norme du gradient : 2.5682576356165335e-05\n",
      "\n",
      "Itération 264 :\n",
      "     - Fonction objective : 0.2832366407733147\n",
      "     - Norme du gradient : 2.466747494857547e-05\n",
      "\n",
      "Itération 265 :\n",
      "     - Fonction objective : 0.2832363965605871\n",
      "     - Norme du gradient : 2.369249532835653e-05\n",
      "\n",
      "Itération 266 :\n",
      "     - Fonction objective : 0.2832361620003448\n",
      "     - Norme du gradient : 2.2756051685646984e-05\n",
      "\n",
      "Itération 267 :\n",
      "     - Fonction objective : 0.28323593671107394\n",
      "     - Norme du gradient : 2.1856620889570676e-05\n",
      "\n",
      "Itération 268 :\n",
      "     - Fonction objective : 0.2832357203263401\n",
      "     - Norme du gradient : 2.0992740010858687e-05\n",
      "\n",
      "Itération 269 :\n",
      "     - Fonction objective : 0.28323551249419243\n",
      "     - Norme du gradient : 2.0163003942378403e-05\n",
      "\n",
      "Itération 270 :\n",
      "     - Fonction objective : 0.2832353128765914\n",
      "     - Norme du gradient : 1.9366063113728542e-05\n",
      "\n",
      "Itération 271 :\n",
      "     - Fonction objective : 0.2832351211488567\n",
      "     - Norme du gradient : 1.8600621296147554e-05\n",
      "\n",
      "Itération 272 :\n",
      "     - Fonction objective : 0.2832349369991427\n",
      "     - Norme du gradient : 1.7865433494194685e-05\n",
      "\n",
      "Itération 273 :\n",
      "     - Fonction objective : 0.2832347601279284\n",
      "     - Norme du gradient : 1.7159303920756993e-05\n",
      "\n",
      "Itération 274 :\n",
      "     - Fonction objective : 0.2832345902475326\n",
      "     - Norme du gradient : 1.6481084052093482e-05\n",
      "\n",
      "Itération 275 :\n",
      "     - Fonction objective : 0.28323442708164326\n",
      "     - Norme du gradient : 1.5829670759755147e-05\n",
      "\n",
      "Itération 276 :\n",
      "     - Fonction objective : 0.2832342703648706\n",
      "     - Norme du gradient : 1.5204004516343007e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 277 :\n",
      "     - Fonction objective : 0.283234119842313\n",
      "     - Norme du gradient : 1.460306767217641e-05\n",
      "\n",
      "Itération 278 :\n",
      "     - Fonction objective : 0.2832339752691457\n",
      "     - Norme du gradient : 1.4025882800082651e-05\n",
      "\n",
      "Itération 279 :\n",
      "     - Fonction objective : 0.2832338364102192\n",
      "     - Norme du gradient : 1.3471511105608015e-05\n",
      "\n",
      "Itération 280 :\n",
      "     - Fonction objective : 0.2832337030396789\n",
      "     - Norme du gradient : 1.2939050900058412e-05\n",
      "\n",
      "Itération 281 :\n",
      "     - Fonction objective : 0.28323357494059614\n",
      "     - Norme du gradient : 1.2427636133899945e-05\n",
      "\n",
      "Itération 282 :\n",
      "     - Fonction objective : 0.28323345190461763\n",
      "     - Norme du gradient : 1.1936434988128034e-05\n",
      "\n",
      "Itération 283 :\n",
      "     - Fonction objective : 0.283233333731625\n",
      "     - Norme du gradient : 1.146464852130176e-05\n",
      "\n",
      "Itération 284 :\n",
      "     - Fonction objective : 0.28323322022940817\n",
      "     - Norme du gradient : 1.1011509370069783e-05\n",
      "\n",
      "Itération 285 :\n",
      "     - Fonction objective : 0.2832331112133559\n",
      "     - Norme du gradient : 1.057628050104069e-05\n",
      "\n",
      "Itération 286 :\n",
      "     - Fonction objective : 0.283233006506153\n",
      "     - Norme du gradient : 1.0158254012000403e-05\n",
      "\n",
      "Itération 287 :\n",
      "     - Fonction objective : 0.28323290593749245\n",
      "     - Norme du gradient : 9.756749980503622e-06\n",
      "\n",
      "Itération 288 :\n",
      "     - Fonction objective : 0.28323280934379846\n",
      "     - Norme du gradient : 9.371115357973252e-06\n",
      "\n",
      "Itération 289 :\n",
      "     - Fonction objective : 0.283232716567961\n",
      "     - Norme du gradient : 9.000722907517932e-06\n",
      "\n",
      "Itération 290 :\n",
      "     - Fonction objective : 0.2832326274590801\n",
      "     - Norme du gradient : 8.644970183723946e-06\n",
      "\n",
      "Itération 291 :\n",
      "     - Fonction objective : 0.2832325418722193\n",
      "     - Norme du gradient : 8.303278552776924e-06\n",
      "\n",
      "Itération 292 :\n",
      "     - Fonction objective : 0.28323245966817123\n",
      "     - Norme du gradient : 7.975092251307983e-06\n",
      "\n",
      "Itération 293 :\n",
      "     - Fonction objective : 0.28323238071323\n",
      "     - Norme du gradient : 7.659877482442968e-06\n",
      "\n",
      "Itération 294 :\n",
      "     - Fonction objective : 0.28323230487897566\n",
      "     - Norme du gradient : 7.3571215475802326e-06\n",
      "\n",
      "Itération 295 :\n",
      "     - Fonction objective : 0.2832322320420628\n",
      "     - Norme du gradient : 7.0663320124807175e-06\n",
      "\n",
      "Itération 296 :\n",
      "     - Fonction objective : 0.28323216208402247\n",
      "     - Norme du gradient : 6.787035906323672e-06\n",
      "\n",
      "Itération 297 :\n",
      "     - Fonction objective : 0.2832320948910665\n",
      "     - Norme du gradient : 6.518778952413479e-06\n",
      "\n",
      "Itération 298 :\n",
      "     - Fonction objective : 0.2832320303539063\n",
      "     - Norme du gradient : 6.26112482929909e-06\n",
      "\n",
      "Itération 299 :\n",
      "     - Fonction objective : 0.2832319683675713\n",
      "     - Norme du gradient : 6.013654461094549e-06\n",
      "\n",
      "Itération 300 :\n",
      "     - Fonction objective : 0.28323190883123966\n",
      "     - Norme du gradient : 5.775965335846033e-06\n",
      "\n",
      "Itération 301 :\n",
      "     - Fonction objective : 0.2832318516480767\n",
      "     - Norme du gradient : 5.547670850850338e-06\n",
      "\n",
      "Itération 302 :\n",
      "     - Fonction objective : 0.28323179672507276\n",
      "     - Norme du gradient : 5.3283996838359625e-06\n",
      "\n",
      "Itération 303 :\n",
      "     - Fonction objective : 0.2832317439728951\n",
      "     - Norme du gradient : 5.117795189012093e-06\n",
      "\n",
      "Itération 304 :\n",
      "     - Fonction objective : 0.2832316933057423\n",
      "     - Norme du gradient : 4.915514816977862e-06\n",
      "\n",
      "Itération 305 :\n",
      "     - Fonction objective : 0.28323164464120393\n",
      "     - Norme du gradient : 4.721229557565506e-06\n",
      "\n",
      "Itération 306 :\n",
      "     - Fonction objective : 0.2832315979001267\n",
      "     - Norme du gradient : 4.534623404701943e-06\n",
      "\n",
      "Itération 307 :\n",
      "     - Fonction objective : 0.28323155300648645\n",
      "     - Norme du gradient : 4.355392842426406e-06\n",
      "\n",
      "Itération 308 :\n",
      "     - Fonction objective : 0.28323150988726303\n",
      "     - Norme du gradient : 4.183246351216562e-06\n",
      "\n",
      "Itération 309 :\n",
      "     - Fonction objective : 0.28323146847232283\n",
      "     - Norme du gradient : 4.017903933830702e-06\n",
      "\n",
      "Itération 310 :\n",
      "     - Fonction objective : 0.28323142869430434\n",
      "     - Norme du gradient : 3.85909665989409e-06\n",
      "\n",
      "Itération 311 :\n",
      "     - Fonction objective : 0.28323139048850815\n",
      "     - Norme du gradient : 3.706566228477934e-06\n",
      "\n",
      "Itération 312 :\n",
      "     - Fonction objective : 0.28323135379279196\n",
      "     - Norme du gradient : 3.5600645479736223e-06\n",
      "\n",
      "Itération 313 :\n",
      "     - Fonction objective : 0.2832313185474713\n",
      "     - Norme du gradient : 3.4193533325705978e-06\n",
      "\n",
      "Itération 314 :\n",
      "     - Fonction objective : 0.28323128469521813\n",
      "     - Norme du gradient : 3.2842037146817226e-06\n",
      "\n",
      "Itération 315 :\n",
      "     - Fonction objective : 0.2832312521809723\n",
      "     - Norme du gradient : 3.154395872689987e-06\n",
      "\n",
      "Itération 316 :\n",
      "     - Fonction objective : 0.2832312209518489\n",
      "     - Norme du gradient : 3.029718673406705e-06\n",
      "\n",
      "Itération 317 :\n",
      "     - Fonction objective : 0.2832311909570539\n",
      "     - Norme du gradient : 2.909969328663011e-06\n",
      "\n",
      "Itération 318 :\n",
      "     - Fonction objective : 0.2832311621477997\n",
      "     - Norme du gradient : 2.794953065472924e-06\n",
      "\n",
      "Itération 319 :\n",
      "     - Fonction objective : 0.28323113447722886\n",
      "     - Norme du gradient : 2.68448280923526e-06\n",
      "\n",
      "Itération 320 :\n",
      "     - Fonction objective : 0.283231107900335\n",
      "     - Norme du gradient : 2.578378879453572e-06\n",
      "\n",
      "Itération 321 :\n",
      "     - Fonction objective : 0.28323108237388983\n",
      "     - Norme du gradient : 2.4764686974868756e-06\n",
      "\n",
      "Itération 322 :\n",
      "     - Fonction objective : 0.2832310578563759\n",
      "     - Norme du gradient : 2.378586505848272e-06\n",
      "\n",
      "Itération 323 :\n",
      "     - Fonction objective : 0.28323103430791347\n",
      "     - Norme du gradient : 2.284573098599775e-06\n",
      "\n",
      "Itération 324 :\n",
      "     - Fonction objective : 0.2832310116902023\n",
      "     - Norme du gradient : 2.1942755624037814e-06\n",
      "\n",
      "Itération 325 :\n",
      "     - Fonction objective : 0.283230989966454\n",
      "     - Norme du gradient : 2.1075470278073954e-06\n",
      "\n",
      "Itération 326 :\n",
      "     - Fonction objective : 0.2832309691013346\n",
      "     - Norme du gradient : 2.024246430358738e-06\n",
      "\n",
      "Itération 327 :\n",
      "     - Fonction objective : 0.2832309490609071\n",
      "     - Norme du gradient : 1.9442382811657667e-06\n",
      "\n",
      "Itération 328 :\n",
      "     - Fonction objective : 0.2832309298125756\n",
      "     - Norme du gradient : 1.867392446521452e-06\n",
      "\n",
      "Itération 329 :\n",
      "     - Fonction objective : 0.2832309113250328\n",
      "     - Norme du gradient : 1.793583936241704e-06\n",
      "\n",
      "Itération 330 :\n",
      "     - Fonction objective : 0.2832308935682081\n",
      "     - Norme du gradient : 1.7226927003680663e-06\n",
      "\n",
      "Itération 331 :\n",
      "     - Fonction objective : 0.2832308765132206\n",
      "     - Norme du gradient : 1.6546034339043443e-06\n",
      "\n",
      "Itération 332 :\n",
      "     - Fonction objective : 0.28323086013232956\n",
      "     - Norme du gradient : 1.5892053892744024e-06\n",
      "\n",
      "Itération 333 :\n",
      "     - Fonction objective : 0.28323084439889185\n",
      "     - Norme du gradient : 1.5263921961886257e-06\n",
      "\n",
      "Itération 334 :\n",
      "     - Fonction objective : 0.2832308292873167\n",
      "     - Norme du gradient : 1.466061688633254e-06\n",
      "\n",
      "Itération 335 :\n",
      "     - Fonction objective : 0.2832308147730252\n",
      "     - Norme du gradient : 1.40811573869825e-06\n",
      "\n",
      "Itération 336 :\n",
      "     - Fonction objective : 0.2832308008324093\n",
      "     - Norme du gradient : 1.3524600969675933e-06\n",
      "\n",
      "Itération 337 :\n",
      "     - Fonction objective : 0.2832307874427956\n",
      "     - Norme du gradient : 1.2990042392257137e-06\n",
      "\n",
      "Itération 338 :\n",
      "     - Fonction objective : 0.28323077458240464\n",
      "     - Norme du gradient : 1.2476612192178767e-06\n",
      "\n",
      "Itération 339 :\n",
      "     - Fonction objective : 0.2832307622303197\n",
      "     - Norme du gradient : 1.1983475272323072e-06\n",
      "\n",
      "Itération 340 :\n",
      "     - Fonction objective : 0.2832307503664497\n",
      "     - Norme du gradient : 1.1509829542701894e-06\n",
      "\n",
      "Itération 341 :\n",
      "     - Fonction objective : 0.2832307389714976\n",
      "     - Norme du gradient : 1.1054904615860209e-06\n",
      "\n",
      "Itération 342 :\n",
      "     - Fonction objective : 0.2832307280269306\n",
      "     - Norme du gradient : 1.0617960553835066e-06\n",
      "\n",
      "Itération 343 :\n",
      "     - Fonction objective : 0.283230717514946\n",
      "     - Norme du gradient : 1.0198286664640925e-06\n",
      "\n",
      "Itération 344 :\n",
      "     - Fonction objective : 0.2832307074184471\n",
      "     - Norme du gradient : 9.795200346325065e-07\n",
      "\n",
      "Itération 345 :\n",
      "     - Fonction objective : 0.283230697721011\n",
      "     - Norme du gradient : 9.408045976713449e-07\n",
      "\n",
      "Itération 346 :\n",
      "     - Fonction objective : 0.2832306884068649\n",
      "     - Norme du gradient : 9.036193847037236e-07\n",
      "\n",
      "Itération 347 :\n",
      "     - Fonction objective : 0.2832306794608605\n",
      "     - Norme du gradient : 8.679039137704596e-07\n",
      "\n",
      "Itération 348 :\n",
      "     - Fonction objective : 0.28323067086844544\n",
      "     - Norme du gradient : 8.336000934564718e-07\n",
      "\n",
      "Itération 349 :\n",
      "     - Fonction objective : 0.28323066261564434\n",
      "     - Norme du gradient : 8.00652128404275e-07\n",
      "\n",
      "Itération 350 :\n",
      "     - Fonction objective : 0.283230654689035\n",
      "     - Norme du gradient : 7.690064285622852e-07\n",
      "\n",
      "Itération 351 :\n",
      "     - Fonction objective : 0.2832306470757241\n",
      "     - Norme du gradient : 7.386115220213304e-07\n",
      "\n",
      "Itération 352 :\n",
      "     - Fonction objective : 0.2832306397633285\n",
      "     - Norme du gradient : 7.094179712939772e-07\n",
      "\n",
      "Itération 353 :\n",
      "     - Fonction objective : 0.2832306327399552\n",
      "     - Norme du gradient : 6.813782929049747e-07\n",
      "\n",
      "Itération 354 :\n",
      "     - Fonction objective : 0.28323062599417903\n",
      "     - Norme du gradient : 6.544468801589912e-07\n",
      "\n",
      "Itération 355 :\n",
      "     - Fonction objective : 0.28323061951502976\n",
      "     - Norme du gradient : 6.285799289610179e-07\n",
      "\n",
      "Itération 356 :\n",
      "     - Fonction objective : 0.28323061329196786\n",
      "     - Norme du gradient : 6.03735366568886e-07\n",
      "\n",
      "Itération 357 :\n",
      "     - Fonction objective : 0.28323060731487226\n",
      "     - Norme du gradient : 5.798727831614213e-07\n",
      "\n",
      "Itération 358 :\n",
      "     - Fonction objective : 0.28323060157402064\n",
      "     - Norme du gradient : 5.569533661120656e-07\n",
      "\n",
      "Itération 359 :\n",
      "     - Fonction objective : 0.28323059606007556\n",
      "     - Norme du gradient : 5.349398368593988e-07\n",
      "\n",
      "Itération 360 :\n",
      "     - Fonction objective : 0.28323059076406887\n",
      "     - Norme du gradient : 5.137963902735294e-07\n",
      "\n",
      "Itération 361 :\n",
      "     - Fonction objective : 0.28323058567738607\n",
      "     - Norme du gradient : 4.934886364194522e-07\n",
      "\n",
      "Itération 362 :\n",
      "     - Fonction objective : 0.2832305807917541\n",
      "     - Norme du gradient : 4.7398354462056196e-07\n",
      "\n",
      "Itération 363 :\n",
      "     - Fonction objective : 0.2832305760992259\n",
      "     - Norme du gradient : 4.5524938973490946e-07\n",
      "\n",
      "Itération 364 :\n",
      "     - Fonction objective : 0.2832305715921697\n",
      "     - Norme du gradient : 4.372557005538632e-07\n",
      "\n",
      "Itération 365 :\n",
      "     - Fonction objective : 0.28323056726325496\n",
      "     - Norme du gradient : 4.1997321024005217e-07\n",
      "\n",
      "Itération 366 :\n",
      "     - Fonction objective : 0.2832305631054396\n",
      "     - Norme du gradient : 4.0337380872546565e-07\n",
      "\n",
      "Itération 367 :\n",
      "     - Fonction objective : 0.28323055911196143\n",
      "     - Norme du gradient : 3.8743049698979105e-07\n",
      "\n",
      "Itération 368 :\n",
      "     - Fonction objective : 0.2832305552763254\n",
      "     - Norme du gradient : 3.721173431464066e-07\n",
      "\n",
      "Itération 369 :\n",
      "     - Fonction objective : 0.2832305515922926\n",
      "     - Norme du gradient : 3.574094402639678e-07\n",
      "\n",
      "Itération 370 :\n",
      "     - Fonction objective : 0.28323054805387055\n",
      "     - Norme du gradient : 3.4328286585541667e-07\n",
      "\n",
      "Itération 371 :\n",
      "     - Fonction objective : 0.2832305446553042\n",
      "     - Norme du gradient : 3.2971464296776443e-07\n",
      "\n",
      "Itération 372 :\n",
      "     - Fonction objective : 0.2832305413910663\n",
      "     - Norme du gradient : 3.1668270280964243e-07\n",
      "\n",
      "Itération 373 :\n",
      "     - Fonction objective : 0.28323053825584665\n",
      "     - Norme du gradient : 3.0416584885679164e-07\n",
      "\n",
      "Itération 374 :\n",
      "     - Fonction objective : 0.28323053524454667\n",
      "     - Norme du gradient : 2.921437223757452e-07\n",
      "\n",
      "Itération 375 :\n",
      "     - Fonction objective : 0.28323053235226764\n",
      "     - Norme du gradient : 2.805967693096192e-07\n",
      "\n",
      "Itération 376 :\n",
      "     - Fonction objective : 0.283230529574306\n",
      "     - Norme du gradient : 2.695062084739932e-07\n",
      "\n",
      "Itération 377 :\n",
      "     - Fonction objective : 0.2832305269061429\n",
      "     - Norme du gradient : 2.58854001009304e-07\n",
      "\n",
      "Itération 378 :\n",
      "     - Fonction objective : 0.2832305243434387\n",
      "     - Norme du gradient : 2.4862282103958156e-07\n",
      "\n",
      "Itération 379 :\n",
      "     - Fonction objective : 0.28323052188202497\n",
      "     - Norme du gradient : 2.387960274930463e-07\n",
      "\n",
      "Itération 380 :\n",
      "     - Fonction objective : 0.28323051951789874\n",
      "     - Norme du gradient : 2.293576370343219e-07\n",
      "\n",
      "Itération 381 :\n",
      "     - Fonction objective : 0.28323051724721426\n",
      "     - Norme du gradient : 2.2029229806811682e-07\n",
      "\n",
      "Itération 382 :\n",
      "     - Fonction objective : 0.28323051506627844\n",
      "     - Norme du gradient : 2.1158526576924727e-07\n",
      "\n",
      "Itération 383 :\n",
      "     - Fonction objective : 0.2832305129715438\n",
      "     - Norme du gradient : 2.0322237810070442e-07\n",
      "\n",
      "Itération 384 :\n",
      "     - Fonction objective : 0.283230510959603\n",
      "     - Norme du gradient : 1.9519003277821605e-07\n",
      "\n",
      "Itération 385 :\n",
      "     - Fonction objective : 0.28323050902718444\n",
      "     - Norme du gradient : 1.874751651467825e-07\n",
      "\n",
      "Itération 386 :\n",
      "     - Fonction objective : 0.28323050717114456\n",
      "     - Norme du gradient : 1.800652269307226e-07\n",
      "\n",
      "Itération 387 :\n",
      "     - Fonction objective : 0.2832305053884641\n",
      "     - Norme du gradient : 1.7294816582354566e-07\n",
      "\n",
      "Itération 388 :\n",
      "     - Fonction objective : 0.28323050367624425\n",
      "     - Norme du gradient : 1.6611240588515034e-07\n",
      "\n",
      "Itération 389 :\n",
      "     - Fonction objective : 0.28323050203169947\n",
      "     - Norme du gradient : 1.595468287136306e-07\n",
      "\n",
      "Itération 390 :\n",
      "     - Fonction objective : 0.28323050045215536\n",
      "     - Norme du gradient : 1.5324075536026482e-07\n",
      "\n",
      "Itération 391 :\n",
      "     - Fonction objective : 0.28323049893504254\n",
      "     - Norme du gradient : 1.4718392896144228e-07\n",
      "\n",
      "Itération 392 :\n",
      "     - Fonction objective : 0.2832304974778933\n",
      "     - Norme du gradient : 1.4136649805450512e-07\n",
      "\n",
      "Itération 393 :\n",
      "     - Fonction objective : 0.28323049607833817\n",
      "     - Norme du gradient : 1.3577900055537135e-07\n",
      "\n",
      "Itération 394 :\n",
      "     - Fonction objective : 0.28323049473409984\n",
      "     - Norme du gradient : 1.3041234836775826e-07\n",
      "\n",
      "Itération 395 :\n",
      "     - Fonction objective : 0.28323049344299284\n",
      "     - Norme du gradient : 1.2525781260156505e-07\n",
      "\n",
      "Itération 396 :\n",
      "     - Fonction objective : 0.2832304922029163\n",
      "     - Norme du gradient : 1.2030700937530436e-07\n",
      "\n",
      "Itération 397 :\n",
      "     - Fonction objective : 0.28323049101185405\n",
      "     - Norme du gradient : 1.155518861794137e-07\n",
      "\n",
      "Itération 398 :\n",
      "     - Fonction objective : 0.2832304898678682\n",
      "     - Norme du gradient : 1.109847087793385e-07\n",
      "\n",
      "Itération 399 :\n",
      "     - Fonction objective : 0.28323048876909845\n",
      "     - Norme du gradient : 1.0659804863506526e-07\n",
      "\n",
      "Itération 400 :\n",
      "     - Fonction objective : 0.2832304877137572\n",
      "     - Norme du gradient : 1.0238477081911797e-07\n",
      "\n",
      "Itération 401 :\n",
      "     - Fonction objective : 0.2832304867001281\n",
      "     - Norme du gradient : 9.833802241149451e-08\n",
      "\n",
      "Itération 402 :\n",
      "     - Fonction objective : 0.28323048572656284\n",
      "     - Norme du gradient : 9.445122135281095e-08\n",
      "\n",
      "Itération 403 :\n",
      "     - Fonction objective : 0.28323048479147767\n",
      "     - Norme du gradient : 9.071804573939197e-08\n",
      "\n",
      "Itération 404 :\n",
      "     - Fonction objective : 0.28323048389335137\n",
      "     - Norme du gradient : 8.71324235398763e-08\n",
      "\n",
      "Itération 405 :\n",
      "     - Fonction objective : 0.2832304830307239\n",
      "     - Norme du gradient : 8.368852271952195e-08\n",
      "\n",
      "Itération 406 :\n",
      "     - Fonction objective : 0.283230482202192\n",
      "     - Norme du gradient : 8.038074175419521e-08\n",
      "\n",
      "Itération 407 :\n",
      "     - Fonction objective : 0.2832304814064065\n",
      "     - Norme du gradient : 7.720370051947306e-08\n",
      "\n",
      "Itération 408 :\n",
      "     - Fonction objective : 0.2832304806420754\n",
      "     - Norme du gradient : 7.415223153980541e-08\n",
      "\n",
      "Itération 409 :\n",
      "     - Fonction objective : 0.28323047990795447\n",
      "     - Norme du gradient : 7.122137158369686e-08\n",
      "\n",
      "Itération 410 :\n",
      "     - Fonction objective : 0.28323047920284894\n",
      "     - Norme du gradient : 6.840635359089608e-08\n",
      "\n",
      "Itération 411 :\n",
      "     - Fonction objective : 0.28323047852561267\n",
      "     - Norme du gradient : 6.570259891865767e-08\n",
      "\n",
      "Itération 412 :\n",
      "     - Fonction objective : 0.28323047787514466\n",
      "     - Norme du gradient : 6.310570989480224e-08\n",
      "\n",
      "Itération 413 :\n",
      "     - Fonction objective : 0.28323047725038597\n",
      "     - Norme du gradient : 6.061146266451707e-08\n",
      "\n",
      "Itération 414 :\n",
      "     - Fonction objective : 0.2832304766503207\n",
      "     - Norme du gradient : 5.821580032078398e-08\n",
      "\n",
      "Itération 415 :\n",
      "     - Fonction objective : 0.2832304760739732\n",
      "     - Norme du gradient : 5.5914826305198794e-08\n",
      "\n",
      "Itération 416 :\n",
      "     - Fonction objective : 0.2832304755204059\n",
      "     - Norme du gradient : 5.370479807042398e-08\n",
      "\n",
      "Itération 417 :\n",
      "     - Fonction objective : 0.28323047498871823\n",
      "     - Norme du gradient : 5.1582120993204235e-08\n",
      "\n",
      "Itération 418 :\n",
      "     - Fonction objective : 0.28323047447804517\n",
      "     - Norme du gradient : 4.9543342527170574e-08\n",
      "\n",
      "Itération 419 :\n",
      "     - Fonction objective : 0.2832304739875567\n",
      "     - Norme du gradient : 4.7585146587704254e-08\n",
      "\n",
      "Itération 420 :\n",
      "     - Fonction objective : 0.28323047351645453\n",
      "     - Norme du gradient : 4.57043481580062e-08\n",
      "\n",
      "Itération 421 :\n",
      "     - Fonction objective : 0.28323047306397303\n",
      "     - Norme du gradient : 4.389788810881949e-08\n",
      "\n",
      "Itération 422 :\n",
      "     - Fonction objective : 0.28323047262937523\n",
      "     - Norme du gradient : 4.216282822265214e-08\n",
      "\n",
      "Itération 423 :\n",
      "     - Fonction objective : 0.28323047221195496\n",
      "     - Norme du gradient : 4.049634641478301e-08\n",
      "\n",
      "Itération 424 :\n",
      "     - Fonction objective : 0.2832304718110335\n",
      "     - Norme du gradient : 3.889573214315522e-08\n",
      "\n",
      "Itération 425 :\n",
      "     - Fonction objective : 0.28323047142595825\n",
      "     - Norme du gradient : 3.735838199957104e-08\n",
      "\n",
      "Itération 426 :\n",
      "     - Fonction objective : 0.28323047105610333\n",
      "     - Norme du gradient : 3.588179547541869e-08\n",
      "\n",
      "Itération 427 :\n",
      "     - Fonction objective : 0.2832304707008669\n",
      "     - Norme du gradient : 3.446357089429497e-08\n",
      "\n",
      "Itération 428 :\n",
      "     - Fonction objective : 0.2832304703596708\n",
      "     - Norme du gradient : 3.3101401506009573e-08\n",
      "\n",
      "Itération 429 :\n",
      "     - Fonction objective : 0.2832304700319607\n",
      "     - Norme du gradient : 3.17930717342849e-08\n",
      "\n",
      "Itération 430 :\n",
      "     - Fonction objective : 0.2832304697172032\n",
      "     - Norme du gradient : 3.053645357332522e-08\n",
      "\n",
      "Itération 431 :\n",
      "     - Fonction objective : 0.2832304694148861\n",
      "     - Norme du gradient : 2.9329503126643137e-08\n",
      "\n",
      "Itération 432 :\n",
      "     - Fonction objective : 0.28323046912451844\n",
      "     - Norme du gradient : 2.8170257282504324e-08\n",
      "\n",
      "Itération 433 :\n",
      "     - Fonction objective : 0.2832304688456273\n",
      "     - Norme du gradient : 2.705683052097772e-08\n",
      "\n",
      "Itération 434 :\n",
      "     - Fonction objective : 0.2832304685777597\n",
      "     - Norme du gradient : 2.598741184719842e-08\n",
      "\n",
      "Itération 435 :\n",
      "     - Fonction objective : 0.2832304683204792\n",
      "     - Norme du gradient : 2.4960261845583486e-08\n",
      "\n",
      "Itération 436 :\n",
      "     - Fonction objective : 0.28323046807336805\n",
      "     - Norme du gradient : 2.3973709850908434e-08\n",
      "\n",
      "Itération 437 :\n",
      "     - Fonction objective : 0.28323046783602396\n",
      "     - Norme du gradient : 2.302615123070416e-08\n",
      "\n",
      "Itération 438 :\n",
      "     - Fonction objective : 0.2832304676080602\n",
      "     - Norme du gradient : 2.2116044775593052e-08\n",
      "\n",
      "Itération 439 :\n",
      "     - Fonction objective : 0.2832304673891071\n",
      "     - Norme du gradient : 2.124191019224568e-08\n",
      "\n",
      "Itération 440 :\n",
      "     - Fonction objective : 0.2832304671788084\n",
      "     - Norme du gradient : 2.0402325695852052e-08\n",
      "\n",
      "Itération 441 :\n",
      "     - Fonction objective : 0.2832304669768215\n",
      "     - Norme du gradient : 1.9595925697504952e-08\n",
      "\n",
      "Itération 442 :\n",
      "     - Fonction objective : 0.2832304667828179\n",
      "     - Norme du gradient : 1.8821398582987093e-08\n",
      "\n",
      "Itération 443 :\n",
      "     - Fonction objective : 0.2832304665964825\n",
      "     - Norme du gradient : 1.8077484579596266e-08\n",
      "\n",
      "Itération 444 :\n",
      "     - Fonction objective : 0.2832304664175118\n",
      "     - Norme du gradient : 1.7362973707002148e-08\n",
      "\n",
      "Itération 445 :\n",
      "     - Fonction objective : 0.28323046624561526\n",
      "     - Norme du gradient : 1.6676703809272158e-08\n",
      "\n",
      "Itération 446 :\n",
      "     - Fonction objective : 0.2832304660805127\n",
      "     - Norme du gradient : 1.6017558664474394e-08\n",
      "\n",
      "Itération 447 :\n",
      "     - Fonction objective : 0.2832304659219358\n",
      "     - Norme du gradient : 1.5384466169343317e-08\n",
      "\n",
      "Itération 448 :\n",
      "     - Fonction objective : 0.2832304657696266\n",
      "     - Norme du gradient : 1.4776396595359692e-08\n",
      "\n",
      "Itération 449 :\n",
      "     - Fonction objective : 0.2832304656233376\n",
      "     - Norme du gradient : 1.4192360913931281e-08\n",
      "\n",
      "Itération 450 :\n",
      "     - Fonction objective : 0.28323046548283054\n",
      "     - Norme du gradient : 1.3631409187697829e-08\n",
      "\n",
      "Itération 451 :\n",
      "     - Fonction objective : 0.28323046534787666\n",
      "     - Norme du gradient : 1.3092629025543674e-08\n",
      "\n",
      "Itération 452 :\n",
      "     - Fonction objective : 0.28323046521825723\n",
      "     - Norme du gradient : 1.2575144098468199e-08\n",
      "\n",
      "Itération 453 :\n",
      "     - Fonction objective : 0.28323046509376054\n",
      "     - Norme du gradient : 1.2078112714314481e-08\n",
      "\n",
      "Itération 454 :\n",
      "     - Fonction objective : 0.2832304649741851\n",
      "     - Norme du gradient : 1.1600726448717576e-08\n",
      "\n",
      "Itération 455 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     - Fonction objective : 0.2832304648593357\n",
      "     - Norme du gradient : 1.1142208830221927e-08\n",
      "\n",
      "Itération 456 :\n",
      "     - Fonction objective : 0.2832304647490259\n",
      "     - Norme du gradient : 1.0701814077364526e-08\n",
      "\n",
      "Itération 457 :\n",
      "     - Fonction objective : 0.2832304646430758\n",
      "     - Norme du gradient : 1.0278825885568059e-08\n",
      "\n",
      "Itération 458 :\n",
      "     - Fonction objective : 0.28323046454131356\n",
      "     - Norme du gradient : 9.872556262135089e-09\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "Estimation du coefficient directeur : 0.9953296234175988\n",
      "Estimation de la constante : 0.49533532060600916\n"
     ]
    }
   ],
   "source": [
    "a, b = optimisation(x, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59798a3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-887c8701fa2d9f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f69749ebf70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax.scatter(x, y, alpha=0.2, label=\"Données\")\n",
    "\n",
    "z = np.linspace(-10, 10)\n",
    "ax.plot(z, a*z + b, color=\"red\", label=\"Modèle y = {0:0.3f}x + {1:0.3f}\".format(a, b))\n",
    "\n",
    "\n",
    "ax.set(xlim=(-10, 10), ylim=(-10, 10))\n",
    "ax.set(xlabel=\"x\", ylabel=\"y\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97577c2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3fab798c938bbeff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407 ms ± 28.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "optimisation(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7935c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TP\n",
    "\n",
    "C'est maintenant à vous de jouer.\n",
    "En utilisant les différentes fonctions **NumPy** vues notamment au cours du TP n°2, votre objectif est d'augmenter la rapidité d'exécution de chacune de ces fonctions.\n",
    "L'essentiel de votre travail devra se concentrer sur les fonctions `objectif` et `gradient` car c'est là que votre calcul passera la majeure partie de son temps.\n",
    "Pensez à ajouter en commentaire à chaque fois pourquoi vous pensez que les modifications que vous avez effectuées améliorent les performances du code.\n",
    "Pensez également à vérifier que ces mêmes modifications ne changent pas pour autant le résultat (i.e. que ce vous codez est effectivement correcte!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed5a92",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1c3de87bc895cc4b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
